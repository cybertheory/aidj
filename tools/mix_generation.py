from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import os
import json
from typing import List, Dict, Optional, Tuple
import numpy as np
from config import Config

class MixGenerationTool:
    def __init__(self):
        self.sample_rate = Config.DEFAULT_SAMPLE_RATE
        self.channels = Config.DEFAULT_CHANNELS
        
    def load_audio_segment(self, file_path: str) -> Optional[AudioSegment]:
        """Load audio file with improved Windows path handling"""
        try:
            # Normalize path for Windows
            file_path = os.path.normpath(file_path)
            
            # Remove quotes if they exist (sometimes paths come pre-quoted)
            file_path = file_path.strip('"').strip("'")
            
            print(f"Attempting to load: '{file_path}'")
            
            # Try multiple path variations for Windows
            search_paths = [
                file_path,  # Original path
                os.path.join(os.getcwd(), file_path),  # Relative to current directory
                os.path.join(Config.MUSIC_DIR, os.path.basename(file_path)),  # Just filename in music dir
            ]
            
            # Try each path
            for search_path in search_paths:
                search_path = os.path.normpath(search_path)
                print(f"Trying path: '{search_path}'")
                
                if os.path.exists(search_path):
                    print(f"‚úÖ File found at: '{search_path}'")
                    
                    # Load with quoted path for Windows
                    audio = AudioSegment.from_file(search_path)
                    
                    # Normalize format
                    audio = audio.set_frame_rate(self.sample_rate)
                    audio = audio.set_channels(self.channels)
                    
                    print(f"Successfully loaded: {os.path.basename(search_path)} ({len(audio)/1000:.1f}s)")
                    return audio
            
            # If not found, show available files
            print(f"‚ùå File not found: '{file_path}'")
            if os.path.exists(Config.MUSIC_DIR):
                available_files = [f for f in os.listdir(Config.MUSIC_DIR) if f.endswith('.mp3')]
                print(f"Available MP3 files in '{Config.MUSIC_DIR}': {available_files}")
            
            return None
            
        except Exception as e:
            print(f"Error loading '{file_path}': {e}")
            return None
    
    def apply_fade(self, audio: AudioSegment, fade_in_ms: int = 0, fade_out_ms: int = 0) -> AudioSegment:
        """Apply fade in/out to audio segment"""
        if fade_in_ms > 0:
            audio = audio.fade_in(fade_in_ms)
        if fade_out_ms > 0:
            audio = audio.fade_out(fade_out_ms)
        return audio
    
    def crossfade_tracks(self, track1: AudioSegment, track2: AudioSegment, 
                        crossfade_duration_ms: int = 3000) -> AudioSegment:
        """Crossfade between two tracks"""
        # Ensure crossfade duration doesn't exceed track lengths
        max_crossfade = min(len(track1), len(track2), crossfade_duration_ms)
        
        # Apply fade out to first track
        track1_faded = track1.fade_out(max_crossfade)
        
        # Apply fade in to second track
        track2_faded = track2.fade_in(max_crossfade)
        
        # Overlay the faded portion
        crossfaded = track1_faded.overlay(track2_faded, position=len(track1_faded) - max_crossfade)
        
        return crossfaded
    
    def beat_match_tracks(self, track1: AudioSegment, track2: AudioSegment, 
                         track1_bpm: float, track2_bpm: float, target_bpm: Optional[float] = None) -> Tuple[AudioSegment, AudioSegment]:
        """Simple beat matching by tempo adjustment"""
        if not target_bpm:
            target_bpm = (track1_bpm + track2_bpm) / 2
        
        # Calculate speed adjustment ratios
        track1_ratio = target_bpm / track1_bpm if track1_bpm > 0 else 1.0
        track2_ratio = target_bpm / track2_bpm if track2_bpm > 0 else 1.0
        
        # Apply speed changes (within reasonable limits)
        if 0.9 <= track1_ratio <= 1.1:
            track1 = track1._spawn(track1.raw_data, overrides={
                "frame_rate": int(track1.frame_rate * track1_ratio)
            }).set_frame_rate(self.sample_rate)
        
        if 0.9 <= track2_ratio <= 1.1:
            track2 = track2._spawn(track2.raw_data, overrides={
                "frame_rate": int(track2.frame_rate * track2_ratio)
            }).set_frame_rate(self.sample_rate)
        
        return track1, track2
    
    def apply_eq_filter(self, audio: AudioSegment, eq_type: str = "none") -> AudioSegment:
        """Apply basic EQ filtering"""
        try:
            if eq_type == "bass_boost":
                # Simple bass boost using low-pass emphasis
                filtered = audio.low_pass_filter(200)
                attenuated = audio - 3
                return filtered.overlay(attenuated)
            elif eq_type == "treble_boost":
                # Simple treble boost using high-pass emphasis
                filtered = audio.high_pass_filter(3000)
                attenuated = audio - 3
                return filtered.overlay(attenuated)
            elif eq_type == "warm":
                # Warm sound - slight bass boost, treble cut
                filtered = audio.low_pass_filter(8000)
                return filtered + 1
            return audio
        except (TypeError, AttributeError, Exception) as e:
            # Handle mock objects or unsupported operations
            print(f"Warning: EQ filter failed, using original audio: {e}")
            return audio

    
    def generate_mix(self, file_paths: List[str], analyses: List[Dict], 
                    transition_type: str = "crossfade", fade_duration_ms: int = 3000,
                    mix_style: str = "seamless", target_duration_ms: Optional[int] = None) -> Dict:
        """Generate a mix from multiple audio files"""
        
        if not file_paths:
            return {"error": "No files provided"}
        
        try:
            print(f"üéµ Starting mix generation with {len(file_paths)} files")
            print(f"Files to process: {[os.path.basename(f) for f in file_paths]}")
            
            # Ensure directories exist
            Config.ensure_directories()
            
            # Load all audio segments
            segments = []
            for i, file_path in enumerate(file_paths):
                audio = self.load_audio_segment(file_path)
                if audio is None:
                    print(f"Skipping failed file: {os.path.basename(file_path)}")
                    continue
                
                # Apply normalization
                audio = normalize(audio)
                
                # Apply EQ based on analysis
                if i < len(analyses) and 'mood' in analyses[i]:
                    mood = analyses[i]['mood']
                    if mood == "calm":
                        audio = self.apply_eq_filter(audio, "warm")
                    elif mood == "energetic":
                        audio = self.apply_eq_filter(audio, "treble_boost")
                
                segments.append({
                    'audio': audio,
                    'analysis': analyses[i] if i < len(analyses) else {},
                    'file_path': file_path
                })
            
            if not segments:
                return {"error": "No valid audio segments loaded. Check file paths and ensure files exist."}
            
            print(f"‚úÖ Successfully loaded {len(segments)} audio segments")
            
            # Generate mix based on style
            if mix_style == "seamless":
                mixed_audio = self._create_seamless_mix(segments, transition_type, fade_duration_ms)
            elif mix_style == "energetic":
                mixed_audio = self._create_energetic_mix(segments, transition_type, fade_duration_ms)
            else:
                mixed_audio = self._create_basic_mix(segments, transition_type, fade_duration_ms)
            
            # Apply target duration if specified
            if target_duration_ms and len(mixed_audio) > target_duration_ms:
                mixed_audio = mixed_audio[:target_duration_ms].fade_out(2000)
                print(f"‚úÇÔ∏è  Trimmed mix to target duration: {target_duration_ms/1000:.1f}s")
            
            # Final processing
            mixed_audio = normalize(mixed_audio)
            mixed_audio = compress_dynamic_range(mixed_audio)
            
            # Save draft mix - use temp directory or fallback
            try:
                temp_dir = Config.TEMP_DIR
            except:
                import tempfile
                temp_dir = tempfile.gettempdir()
            
            draft_filename = f"mix_draft_{len(segments)}tracks.mp3"
            draft_path = os.path.join(temp_dir, draft_filename)
            mixed_audio.export(draft_path, format="mp3", bitrate="320k")
            
            print(f"üéâ Mix generated successfully: {draft_path}")
            print(f"   Duration: {len(mixed_audio)/1000:.1f}s")
            print(f"   Tracks used: {len(segments)}")
            
            # Generate PyDub code for reproducibility
            pydub_code = self._generate_pydub_code(segments, transition_type, fade_duration_ms, mix_style)
            
            return {
                "status": "success",
                "draft_path": draft_path,
                "duration_ms": len(mixed_audio),
                "duration_seconds": len(mixed_audio) / 1000,
                "tracks_used": len(segments),
                "pydub_code": pydub_code,
                "mix_metadata": {
                    "transition_type": transition_type,
                    "fade_duration_ms": fade_duration_ms,
                    "mix_style": mix_style,
                    "final_bpm": self._estimate_mix_bpm(segments),
                    "energy_progression": self._analyze_energy_progression(segments),
                    "title": f"Generated Mix ({len(segments)} tracks)",
                    "tracks_used": len(segments),
                    "genre": "Lo-Fi Hip Hop",
                    "vibe": "Peaceful Study"
                }
            }
            
        except Exception as e:
            print(f"‚ùå Mix generation error: {str(e)}")
            return {"error": f"Mix generation failed: {str(e)}"}
    
    def _create_seamless_mix(self, segments: List[Dict], transition_type: str, fade_duration_ms: int) -> AudioSegment:
        """Create a seamless mix with smooth transitions"""
        if not segments:
            return AudioSegment.empty()
        
        print(f"üîÑ Creating seamless mix with {transition_type} transitions")
        mixed = segments[0]['audio']
        
        for i in range(1, len(segments)):
            current_segment = segments[i]['audio']
            
            if transition_type == "crossfade":
                mixed = self.crossfade_tracks(mixed, current_segment, fade_duration_ms)
            elif transition_type == "beat_match":
                # Get BPM from analyses
                prev_bpm = segments[i-1]['analysis'].get('tempo', 120)
                curr_bpm = segments[i]['analysis'].get('tempo', 120)
                
                # Beat match before crossfading
                prev_audio = mixed[-30000:]  # Last 30 seconds for beat matching
                matched_prev, matched_curr = self.beat_match_tracks(
                    prev_audio, current_segment, prev_bpm, curr_bpm
                )
                
                # Replace the end of mixed with beat-matched version
                mixed = mixed[:-30000] + matched_prev
                mixed = self.crossfade_tracks(mixed, matched_curr, fade_duration_ms)
            else:
                # Simple concatenation with fades
                mixed = mixed.fade_out(fade_duration_ms // 2)
                current_segment = current_segment.fade_in(fade_duration_ms // 2)
                mixed = mixed + current_segment
        
        return mixed
    
    def _create_energetic_mix(self, segments: List[Dict], transition_type: str, fade_duration_ms: int) -> AudioSegment:
        """Create an energetic mix with quick transitions"""
        # Sort segments by energy level
        segments_sorted = sorted(segments, key=lambda x: x['analysis'].get('energy_mean', 0))
        
        mixed = AudioSegment.empty()
        short_fade = fade_duration_ms // 2
        
        for segment in segments_sorted:
            audio = segment['audio']
            
            # Take energetic portions (skip intro/outro)
            analysis = segment['analysis']
            if 'mixing_metadata' in analysis:
                start_ms = int(analysis['mixing_metadata'].get('best_mix_in', 0) * 1000)
                end_ms = int(analysis['mixing_metadata'].get('best_mix_out', len(audio)/1000) * 1000)
                audio = audio[start_ms:end_ms]
            
            # Boost energy
            audio = audio + 2  # Slight volume boost
            
            if len(mixed) == 0:
                mixed = audio.fade_in(short_fade)
            else:
                mixed = self.crossfade_tracks(mixed, audio, short_fade)
        
        return mixed
    
    def _create_basic_mix(self, segments: List[Dict], transition_type: str, fade_duration_ms: int) -> AudioSegment:
        """Create a basic mix with simple transitions"""
        mixed = AudioSegment.empty()
        
        for i, segment in enumerate(segments):
            audio = segment['audio']
            
            if i == 0:
                mixed = audio.fade_in(fade_duration_ms)
            else:
                if transition_type == "crossfade":
                    mixed = self.crossfade_tracks(mixed, audio, fade_duration_ms)
                else:
                    mixed = mixed + audio.fade_in(fade_duration_ms // 2)
        
        return mixed.fade_out(fade_duration_ms)
    
    def _estimate_mix_bpm(self, segments: List[Dict]) -> float:
        """Estimate overall BPM of the mix"""
        try:
            bpms = []
            for seg in segments:
                if 'analysis' in seg and 'tempo' in seg['analysis']:
                    bpms.append(seg['analysis']['tempo'])
            return sum(bpms) / len(bpms) if bpms else 120.0
        except Exception:
            return 120.0
    
    def _analyze_energy_progression(self, segments: List[Dict]) -> List[str]:
        """Analyze energy progression through the mix"""
        try:
            progression = []
            for seg in segments:
                if 'analysis' in seg:
                    progression.append(seg['analysis'].get('energy_level', 'medium'))
                else:
                    progression.append('medium')
            return progression
        except Exception:
            return ['medium'] * len(segments)
    
    def _generate_pydub_code(self, segments: List[Dict], transition_type: str, 
                           fade_duration_ms: int, mix_style: str) -> str:
        """Generate reproducible PyDub code"""
        code_lines = [
            "from pydub import AudioSegment",
            "from pydub.effects import normalize, compress_dynamic_range",
            "",
            "# Load audio files"
        ]
        
        for i, segment in enumerate(segments):
            filename = os.path.basename(segment['file_path'])
            code_lines.append(f'track_{i} = AudioSegment.from_file("{filename}")')
            code_lines.append(f'track_{i} = normalize(track_{i})')
        
        code_lines.extend([
            "",
            "# Create mix",
            f"mixed = track_0.fade_in({fade_duration_ms})"
        ])
        
        for i in range(1, len(segments)):
            if transition_type == "crossfade":
                code_lines.append(f"mixed = mixed.fade_out({fade_duration_ms}).overlay(track_{i}.fade_in({fade_duration_ms}), position=len(mixed)-{fade_duration_ms})")
            else:
                code_lines.append(f"mixed = mixed + track_{i}.fade_in({fade_duration_ms//2})")
        
        code_lines.extend([
            "",
            "# Final processing",
            "mixed = normalize(mixed)",
            "mixed = compress_dynamic_range(mixed)",
            'mixed.export("final_mix.mp3", format="mp3", bitrate="320k")'
        ])
        
        return "\n".join(code_lines)

    def check_files_exist(self, file_paths: List[str]) -> Dict:
        """Debug method to check which files exist"""
        results = {
            "existing_files": [],
            "missing_files": [],
            "music_dir_contents": []
        }
        
        # Check if music directory exists and get contents
        if os.path.exists(Config.MUSIC_DIR):
            try:
                results["music_dir_contents"] = os.listdir(Config.MUSIC_DIR)
            except Exception as e:
                print(f"Error reading music directory: {e}")
                results["music_dir_contents"] = []
        else:
            results["music_dir_contents"] = []
        
        # Check each file path
        for file_path in file_paths:
            if os.path.exists(file_path):
                results["existing_files"].append(file_path)
            else:
                results["missing_files"].append(file_path)
                
                # Check if file exists in music directory with different path
                filename = os.path.basename(file_path)
                alt_path = os.path.join(Config.MUSIC_DIR, filename)
                if os.path.exists(alt_path) and alt_path not in results["existing_files"]:
                    results["existing_files"].append(alt_path)
        
        return results

# Tool function for LLM integration
def mix_generation_tool(file_paths: List[str], analyses: List[Dict], 
                       transition_type: str = "crossfade", fade_duration_ms: int = 3000,
                       mix_style: str = "seamless", target_duration_ms: Optional[int] = None) -> Dict:
    """Tool function for mix generation"""
    Config.ensure_directories()
    tool = MixGenerationTool()
    
    # Debug: print current working directory and Config.MUSIC_DIR
    print(f"üîç Current working directory: {os.getcwd()}")
    print(f"üîç Music directory: {Config.MUSIC_DIR}")
    print(f"üîç Music directory exists: {os.path.exists(Config.MUSIC_DIR)}")
    
    # First, let's debug what files exist - with safe key access
    file_check = tool.check_files_exist(file_paths)
    existing_files = file_check.get('existing_files', [])
    missing_files = file_check.get('missing_files', [])
    music_dir_contents = file_check.get('music_dir_contents', [])
    
    print(f"üîç File check results:")
    print(f"   Original paths: {file_paths}")
    print(f"   Existing files: {existing_files}")
    print(f"   Missing files: {missing_files}")
    print(f"   Music dir contents: {music_dir_contents}")
    
    # If we have existing files from the check, use those instead
    if existing_files:
        print(f"‚úÖ Using existing files found: {[os.path.basename(p) for p in existing_files]}")
        file_paths = existing_files
    elif music_dir_contents:
        # If no files exist at the given paths, but music directory has files, 
        # create full paths to music directory files
        print("üîÑ Using files from music directory...")
        corrected_paths = []
        for original_path in file_paths:
            filename = os.path.basename(original_path)
            corrected_path = os.path.join(Config.MUSIC_DIR, filename)
            if os.path.exists(corrected_path):
                corrected_paths.append(corrected_path)
        
        if corrected_paths:
            print(f"‚úÖ Using corrected paths: {[os.path.basename(p) for p in corrected_paths]}")
            file_paths = corrected_paths[:len(analyses)]  # Match analyses count
        else:
            # Just use the first few files from music directory
            corrected_paths = [os.path.join(Config.MUSIC_DIR, f) for f in music_dir_contents[:len(analyses)] if f.endswith('.mp3')]
            if corrected_paths:
                print(f"‚úÖ Using available mp3 files: {[os.path.basename(p) for p in corrected_paths]}")
                file_paths = corrected_paths
    
    return tool.generate_mix(file_paths, analyses, transition_type, fade_duration_ms, mix_style, target_duration_ms)

